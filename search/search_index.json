{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Material KNN \u00b6 Pendahuluan \u00b6 Algoritme k-nearest neighbor (k-NN atau KNN) adalah sebuah metode untuk melakukan klasifikasi terhadap objek berdasarkan data pembelajaran yang jaraknya paling dekat dengan objek tersebut. Data pembelajaran diproyeksikan ke ruang berdimensi banyak, dimana masing-masing dimensi merepresentasikan fitur dari data. Ruang ini dibagi menjadi bagian-bagian berdasarkan klasifikasi data pembelajaran. Sebuah titik pada ruang ini ditandai kelas c jika kelas c merupakan klasifikasi yang paling banyak ditemui pada k buah tetangga terdekat titk tersebut. Dekat atau jauhnya tetangga biasanya dihitung berdasarkan jarak Euclidean. Pada fase pembelajaran, algoritme ini hanya melakukan penyimpanan vektor-vektor fitur dan klasifikasi dari data pembelajaran. Pada fase klasifikasi, fitur-fitur yang sama dihitung untuk data test (yang klasifikasinya tidak diketahui). Jarak dari vektor yang baru ini terhadap seluruh vektor data pembelajaran dihitung, dan sejumlah k buah yang paling dekat diambil. Titik yang baru klasifikasinya diprediksikan termasuk pada klasifikasi terbanyak dari titik-titik tersebut. Nilai k yang terbaik untuk algoritme ini tergantung pada data; secara umumnya, nilai k yang tinggi akan mengurangi efek noise pada klasifikasi, tetapi membuat batasan antara setiap klasifikasi menjadi lebih kabur. Nilai k yang bagus dapat dipilih dengan optimasi parameter, misalnya dengan menggunakan cross-validation. Kasus khusus di mana klasifikasi diprediksikan berdasarkan data pembelajaran yang paling dekat (dengan kata lain, k = 1) disebut algoritme nearest neighbor . Ketepatan algoritme k-NN ini sangat dipengaruhi oleh ada atau tidaknya fitur-fitur yang tidak relevan, atau jika bobot fitur tersebut tidak setara dengan relevansinya terhadap klasifikasi. Riset terhadap algoritme ini sebagian besar membahas bagaimana memilih dan memberi bobot terhadap fitur, agar performa klasifikasi menjadi lebih baik. Terdapat beberapa jenis algoritme pencarian tetangga terdekat, diantaranya: Linear scan Pohon kd Pohon Balltree Pohon metrik Locally-sensitive hashing (LSH) Algoritme k-NN ini memiliki konsistensi yang kuat. Ketika jumlah data mendekati tak hingga, algoritme ini menjamin error rate yang tidak lebih dari dua kali Bayes error rate ( error rate minimum untuk distribusi data tertentu). K-means \u00b6 K-means merupakan salah satu algoritma clustering [ 1] . Tujuan algoritma ini yaitu untuk membagi data menjadi beberapa kelompok. Algoritma ini menerima masukan berupa data tanpa label kelas. Hal ini berbeda dengan supervised learning yang menerima masukan berupa vektor (\u00ad x\u00ad1, y1 ) , (\u00ad x\u00ad2 , y2 ) , \u2026, (\u00ad x\u00adi , yi ), di mana xi merupakan data dari suatu data pelatihan dan yi merupakan label kelas untuk xi [ 2] . Pada algoritma pembelajaran ini, komputer mengelompokkan sendiri data-data yang menjadi masukannya tanpa mengetahui terlebih dulu target kelasnya[ 1] . Pembelajaran ini termasuk dalam unsupervised learning. Masukan yang diterima adalah data atau objek dan k buah kelompok ( cluster ) yang diinginkan. Algoritma ini akan mengelompokkan data atau objek ke dalam k buah kelompok tersebut. Pada setiap cluster terdapat titik pusat ( centroid ) yang merepresentasikan cluster tersebut. K-means ditemukan oleh beberapa orang yaitu Lloyd (1957, 1982), Forgey (1965) , Friedman and Rubin (1967) , and McQueen (1967) [ 1] . Ide dari clustering pertama kali ditemukan oleh Lloyd pada tahun 1957, namun hal tersebut baru dipublikasi pada tahun 1982. Pada tahun 1965, Forgey juga mempublikasi teknik yang sama sehingga terkadang dikenal sebagai Lloyd-Forgy pada beberapa sumber. Algoritma K-Means \u00b6 Algoritma untuk melakukan K-Means clustering adalah sebagai berikut[ 3] : Pilih K buah titik centroid secara acak Kelompokkan data sehingga terbentuk K buah cluster dengan titik centroid dari setiap cluster merupakan titik centroid yang telah dipilih sebelumnya Perbaharui nilai titik centroid Ulangi langkah 2 dan 3 sampai nilai dari titik centroid tidak lagi berubah Proses pengelompokkan data ke dalam suatu cluster dapat dilakukan dengan cara menghitung jarak terdekat dari suatu data ke sebuah titik centroid . Perhitungan jarak Minkowski dapat digunakan untuk menghitung jarak antar 2 buah data. Rumus untuk menghitung jarak tersebut adalah[ 4] : Di mana: Pembaharuan suatu titik centroid dapat dilakukan dengan rumus berikut[ 4] : Di mana: Kelebihan dan Kekurangan \u00b6 Ada beberapa kelebihan pada algoritma k-means, yaitu [ 2] : Algoritma k-means memiliki beberapa kelebihan, namun ada kekurangannya juga. Kekurangan dari algoritma tersebut yaitu : Sebelum algoritma dijalankan, k buah titik diinisialisasi secara random sehingga pengelompokkan data yang dihasilkan dapat berbeda-beda [ 1] . Jika nilai random untuk inisialisasi kurang baik, maka pengelompokkan yang dihasilkan pun menjadi kurang optimal. Dapat terjebak dalam masalah yang disebut curse of dimensionality. Hal ini dapat terjadi jika data pelatihan memiliki dimensi yang sangat tinggi (Contoh jika data pelatihan terdiri dari 2 atribut maka dimensinya adalah 2 dimensi. Namun jika ada 20 atribut, maka akan ada 20 dimensi). Salah satu cara kerja algoritma ini adalah mencari jarak terdekat antara k buah titik dengan titik lainnya. Jika mencari jarak antar titik pada 2 dimensi, masih mudah dilakukan. Namun bagaimana mencari jarak antar titik jika terdapat 20 dimensi. Hal ini akan menjadi sulit. Jika hanya terdapat beberapa titik sampel data, maka cukup mudah untuk menghitung dan mencari titik terdekat dengan k titik yang diinisialisasi secara random. Namun jika terdapat banyak sekali titik data (misalnya satu milyar buah data), maka perhitungan dan pencarian titik terdekat akan membutuhkan waktu yang lama. Proses tersebut dapat dipercepat, namun dibutuhkan struktur data yang lebih rumit seperti kD-Tree atau hashing. Implementasi \u00b6 Tools \u00b6 Sebelum menerapkan konsep k-mean clustering pada studi kasus yang telah ditentukan, beberapa tools yang perlu dipersiapkan agar program yang kita rancang bisa dieksekusi dengan baik diantaranya: XAMPP Notepad ++ / Visual Code / Sublime dan lainnya Browser / Chrome Python 3.7 Berikut source code dan penjelasan untuk menyelesaikan study kasus tersebut dengan K-Means Clustering. Pertama \u00b6 buka XAMPP kemudian start apache dan MySQL nya Kedua \u00b6 impor data di phpmyadmin, setelah kita impor akan muncul tampilan seperti berikut ketiga \u00b6 kita buat script connect databasenya menggunakan php <?php $server = \"localhost\"; $username = \"root\"; $password = \"\"; $database = \"gizi\"; // Koneksi dan memilih database di server mysql_connect($server,$username,$password) or die(\"Koneksi gagal\"); mysql_select_db($database) or die(\"Database tidak bisa dibuka\"); ?> keempat \u00b6 membuat tampilan data set ruspini yang terconnect dengan database menggunakan php dan html <?php error_reporting(0); include \"koneksi.php\"; echo \"<h2>Uji Data Set Ruspini</h2> <form method=POST action='aksi.php' enctype='multipart/form-data'> <table> <tr> <td>X</td> <td> : </td> <td> <input type=text name='x' maxlength=100 size=50> </td> </tr> <tr> <td>Y</td> <td> : </td> <td> <input type=text name='y' maxlength=100 size=50> </td> </tr> <tr><td colspan=2> <input type=submit value=Proses> <input type=button value=Batal onclick=self.history.back()></td></tr> </table> </form>\"; echo \"<h2>Tambah Data</h2> <form method=POST action='tambah.php' enctype='multipart/form-data'> <table> <tr> <td>X</td> <td> : </td> <td> <input type=text name='x' maxlength=100 size=50> </td> </tr> <tr> <td>Y</td> <td> : </td> <td> <input type=text name='y' maxlength=100 size=50> </td> </tr> <tr> <td>Kelas</td> <td> : </td> <td> <input type=text name='status' maxlength=100 size=50> </td> </tr> <tr><td colspan=2> <input type=submit value=Simpan> <input type=button value=Batal onclick=self.history.back()></td></tr> </table> </form>\"; /* echo \"<h2>Tambah data</h2> <form method=POST action='tambah.php' enctype='multipart/form-data'> <table> <tr><td>Nama Manggrove</td> <td> : </td><td><input type=text name='nama' maxlength=30 size=30></td></tr> <tr><td>Bentuk Tanaman</td> <td> : </td><td><input type=text name='bt' maxlength=10 size=10></td></tr> <tr><td>Bentuk Akar</td> <td> : </td><td><input type=text name='ba' maxlength=10 size=10></td></tr> <tr><td>Bentuk Buah</td> <td> : </td><td><input type=text name='bb' maxlength=10 size=10></td></tr> <tr><td>Bentuk Daun</td> <td> : </td><td><input type=text name='bd' maxlength=10 size=10></td></tr> <tr><td>Susunan Daun</td> <td> : </td><td><input type=text name='sd' maxlength=10 size=10></td></tr> <tr><td>Tata Letak Daun</td> <td> : </td><td><input type=text name='tld' maxlength=10 size=10></td></tr> <tr><td>Bentuk Ujung Daun</td> <td> : </td><td><input type=text name='bud' maxlength=10 size=10></td></tr> <tr><td>Letak Bunga</td> <td> : </td><td><input type=text name='lb' maxlength=10 size=10></td></tr> <tr><td>Rangkaian Bunga</td> <td> : </td><td><input type=text name='rb' maxlength=10 size=10></td></tr> <tr><td>Daun Mahkota Bunga</td> <td> : </td><td><input type=text name='dmb' maxlength=10 size=10></td></tr> <tr><td>Habitat Tempat Tumbuh</td> <td> : </td><td><input type=text name='htt' maxlength=10 size=10></td></tr> <tr><td colspan=2> <input type=submit value=Simpan> <input type=button value=Batal onclick=self.history.back()></td></tr> </table> </form>\"; */ echo \"========= data Training =========\"; $sql2 = mysql_query(\"SELECT * FROM data ORDER BY id ASC\"); echo \"<table> <thead> <th>Data </th> <th>Kelas</th> <th>X</th> <th>Y</th> </thead>\"; while($data = mysql_fetch_array($sql2)) { echo \"<tr> <td>$data[id]</td> <td>$data[status]</td> <td>$data[x]</td> <td>$data[y]</td> </tr>\"; } echo \"</table>\"; echo \"========= data perhitungan =========\"; $sqls = mysql_query(\"SELECT * FROM sementara ORDER BY id ASC\"); echo \"<table> <thead> <th>Data </th> <th>Kelas</th> <th>X</th> <th>Y</th> </thead>\"; while($data = mysql_fetch_array($sqls)) { echo \"<tr> <td>$data[id]</td> <td>$data[status]</td> <td>$data[x]</td> <td>$data[y]</td> <td>$data[jarak]</td> </tr>\"; } echo \"</table>\"; ?> kelima \u00b6 kita buat script perhitungan KNN dengan mengimpor data X dan Y menggunakan php <?php error_reporting(0); include \"koneksi.php\"; $b_x = $_POST['x']; $b_y = $_POST['y']; if (empty($b_x) or empty($b_y)) { echo \"<script> alert('Ada yang belum anda isi'); window.location = 'javascript:history.go(-1)'; </script>\"; } else { //Membaca jumlah baris data pada database $sql = mysql_query(\"SELECT * FROM data ORDER BY id ASC\"); $numrows = mysql_num_rows($sql); //Menentukan nilai K /*$k=0.3 * $numrows; $k=round($k); $r=$k % 2; if($r!=0) { $k=$k+1; } else { $k=$k; }*/ $k=5; echo \"<b>Nilai K adalah sebesar $k </b><br><br>\"; //Perhitungan dengan KNN for ($i=1; $i <= $numrows; $i++) { $sql1 = mysql_query(\"SELECT * FROM data Where id = $i\"); while($data = mysql_fetch_array($sql1)) { //Pengurangan(KNN) $v1 = $b_x - $data[x]; $v2 = $b_y - $data[y]; //Pengkuadratan(KNN) $hit1 = (pow($v1,2)) + (pow($v2,2)); //Pengakaran(KNN) $hit2 = sqrt($hit1); //Penyimpanan perhitungan ke database sementara mysql_query(\"INSERT INTO sementara (id, jarak, x, y, status) VALUES ('$i', '$hit2', '$data[x]', '$data[y]', '$data[status]')\"); } } //data yang sudah d sorting dari data pertama sampai data nilai K $sql3 = mysql_query(\"SELECT * FROM `sementara` ORDER BY `sementara`.`jarak` ASC LIMIT 0 , $k\"); $x=1; while($data = mysql_fetch_array($sql3)) { //memasukkan data yang sudah di sorting mulai dari pertama sampai data nilai k ke dalam database sementara mysql_query(\"INSERT INTO urut (id, jarak, x, y, status) VALUES ('$x', '$data[jarak]', '$data[x]', '$data[y]', '$data[status]')\"); $x=$x+1; } $sqlrtes = mysql_query(\"SELECT * FROM urut ORDER BY id ASC LIMIT 0 , 1\"); while($datates = mysql_fetch_array($sqlrtes)) { //mencari hasil $sqlrx = mysql_query(\"SELECT * FROM urut ORDER BY id ASC\"); //$hasil_nam = mysql_fetch_array($sql_nam); while($datax = mysql_fetch_array($sqlrx)) { if($datax['jarak']=='0') { $Status = $datax['status']; $x = $datax['x']; $y = $datax['y']; echo \"<br>Terklasifikasi sebagai Kelas <b>$Status</b>, dengan X <b>$x</b>, dan Y <b>$y</b></b>\"; break; } else { $Status = $datax['status']; $x = $datax['x']; $y = $datax['y']; echo \"<br>Terklasifikasi sebagai Kelas <b>$Status</b>, dengan X <b>$x</b>, dan Y <b>$y</b></b>\"; break; } } } //langkah terakhir menghapus histori perhitungan pada database $sqls = mysql_query(\"SELECT * FROM sementara ORDER BY id ASC\"); $numrows1 = mysql_num_rows($sqls); for ($i=1; $i <= $numrows1; $i++) { mysql_query(\"DELETE FROM sementara WHERE id=$i\"); } $sql_urut = mysql_query(\"SELECT * FROM data ORDER BY id ASC\"); $numrows_urut = mysql_num_rows($sql_urut); for ($i=1; $i <= $numrows_urut; $i++) { mysql_query(\"DELETE FROM urut WHERE id=$i\"); } } ?> keenam \u00b6 kita buat script penambahan data dengan mengimpor data X, Y dan kelas menggunakan php <?php error_reporting(0); include \"koneksi.php\"; $b_tinggi = $_POST['tinggi']; $b_berat = $_POST['berat']; $b_status = $_POST['status']; if (empty($b_tinggi) or empty($b_berat) or empty($b_status)) { echo \"<script>alert('Nama something belum anda isi');window.location = 'javascript:history.go(-1)'; </script>\"; } else { mysql_query(\"INSERT INTO data (tinggi, berat, status) VALUES ('$b_tinggi', '$b_berat', '$b_status')\"); echo \"<script>alert('Sukses');window.location = 'javascript:history.go(-1)'; </script>\"; } ?> Refrensi \u00b6 https://id.wikipedia.org/wiki/KNN https://id.wikipedia.org/wiki/K-means","title":"K-Nearest Neighbors"},{"location":"#material-knn","text":"","title":"Material KNN"},{"location":"#pendahuluan","text":"Algoritme k-nearest neighbor (k-NN atau KNN) adalah sebuah metode untuk melakukan klasifikasi terhadap objek berdasarkan data pembelajaran yang jaraknya paling dekat dengan objek tersebut. Data pembelajaran diproyeksikan ke ruang berdimensi banyak, dimana masing-masing dimensi merepresentasikan fitur dari data. Ruang ini dibagi menjadi bagian-bagian berdasarkan klasifikasi data pembelajaran. Sebuah titik pada ruang ini ditandai kelas c jika kelas c merupakan klasifikasi yang paling banyak ditemui pada k buah tetangga terdekat titk tersebut. Dekat atau jauhnya tetangga biasanya dihitung berdasarkan jarak Euclidean. Pada fase pembelajaran, algoritme ini hanya melakukan penyimpanan vektor-vektor fitur dan klasifikasi dari data pembelajaran. Pada fase klasifikasi, fitur-fitur yang sama dihitung untuk data test (yang klasifikasinya tidak diketahui). Jarak dari vektor yang baru ini terhadap seluruh vektor data pembelajaran dihitung, dan sejumlah k buah yang paling dekat diambil. Titik yang baru klasifikasinya diprediksikan termasuk pada klasifikasi terbanyak dari titik-titik tersebut. Nilai k yang terbaik untuk algoritme ini tergantung pada data; secara umumnya, nilai k yang tinggi akan mengurangi efek noise pada klasifikasi, tetapi membuat batasan antara setiap klasifikasi menjadi lebih kabur. Nilai k yang bagus dapat dipilih dengan optimasi parameter, misalnya dengan menggunakan cross-validation. Kasus khusus di mana klasifikasi diprediksikan berdasarkan data pembelajaran yang paling dekat (dengan kata lain, k = 1) disebut algoritme nearest neighbor . Ketepatan algoritme k-NN ini sangat dipengaruhi oleh ada atau tidaknya fitur-fitur yang tidak relevan, atau jika bobot fitur tersebut tidak setara dengan relevansinya terhadap klasifikasi. Riset terhadap algoritme ini sebagian besar membahas bagaimana memilih dan memberi bobot terhadap fitur, agar performa klasifikasi menjadi lebih baik. Terdapat beberapa jenis algoritme pencarian tetangga terdekat, diantaranya: Linear scan Pohon kd Pohon Balltree Pohon metrik Locally-sensitive hashing (LSH) Algoritme k-NN ini memiliki konsistensi yang kuat. Ketika jumlah data mendekati tak hingga, algoritme ini menjamin error rate yang tidak lebih dari dua kali Bayes error rate ( error rate minimum untuk distribusi data tertentu).","title":"Pendahuluan"},{"location":"#k-means","text":"K-means merupakan salah satu algoritma clustering [ 1] . Tujuan algoritma ini yaitu untuk membagi data menjadi beberapa kelompok. Algoritma ini menerima masukan berupa data tanpa label kelas. Hal ini berbeda dengan supervised learning yang menerima masukan berupa vektor (\u00ad x\u00ad1, y1 ) , (\u00ad x\u00ad2 , y2 ) , \u2026, (\u00ad x\u00adi , yi ), di mana xi merupakan data dari suatu data pelatihan dan yi merupakan label kelas untuk xi [ 2] . Pada algoritma pembelajaran ini, komputer mengelompokkan sendiri data-data yang menjadi masukannya tanpa mengetahui terlebih dulu target kelasnya[ 1] . Pembelajaran ini termasuk dalam unsupervised learning. Masukan yang diterima adalah data atau objek dan k buah kelompok ( cluster ) yang diinginkan. Algoritma ini akan mengelompokkan data atau objek ke dalam k buah kelompok tersebut. Pada setiap cluster terdapat titik pusat ( centroid ) yang merepresentasikan cluster tersebut. K-means ditemukan oleh beberapa orang yaitu Lloyd (1957, 1982), Forgey (1965) , Friedman and Rubin (1967) , and McQueen (1967) [ 1] . Ide dari clustering pertama kali ditemukan oleh Lloyd pada tahun 1957, namun hal tersebut baru dipublikasi pada tahun 1982. Pada tahun 1965, Forgey juga mempublikasi teknik yang sama sehingga terkadang dikenal sebagai Lloyd-Forgy pada beberapa sumber.","title":"K-means"},{"location":"#algoritma-k-means","text":"Algoritma untuk melakukan K-Means clustering adalah sebagai berikut[ 3] : Pilih K buah titik centroid secara acak Kelompokkan data sehingga terbentuk K buah cluster dengan titik centroid dari setiap cluster merupakan titik centroid yang telah dipilih sebelumnya Perbaharui nilai titik centroid Ulangi langkah 2 dan 3 sampai nilai dari titik centroid tidak lagi berubah Proses pengelompokkan data ke dalam suatu cluster dapat dilakukan dengan cara menghitung jarak terdekat dari suatu data ke sebuah titik centroid . Perhitungan jarak Minkowski dapat digunakan untuk menghitung jarak antar 2 buah data. Rumus untuk menghitung jarak tersebut adalah[ 4] : Di mana: Pembaharuan suatu titik centroid dapat dilakukan dengan rumus berikut[ 4] : Di mana:","title":"Algoritma K-Means"},{"location":"#kelebihan-dan-kekurangan","text":"Ada beberapa kelebihan pada algoritma k-means, yaitu [ 2] : Algoritma k-means memiliki beberapa kelebihan, namun ada kekurangannya juga. Kekurangan dari algoritma tersebut yaitu : Sebelum algoritma dijalankan, k buah titik diinisialisasi secara random sehingga pengelompokkan data yang dihasilkan dapat berbeda-beda [ 1] . Jika nilai random untuk inisialisasi kurang baik, maka pengelompokkan yang dihasilkan pun menjadi kurang optimal. Dapat terjebak dalam masalah yang disebut curse of dimensionality. Hal ini dapat terjadi jika data pelatihan memiliki dimensi yang sangat tinggi (Contoh jika data pelatihan terdiri dari 2 atribut maka dimensinya adalah 2 dimensi. Namun jika ada 20 atribut, maka akan ada 20 dimensi). Salah satu cara kerja algoritma ini adalah mencari jarak terdekat antara k buah titik dengan titik lainnya. Jika mencari jarak antar titik pada 2 dimensi, masih mudah dilakukan. Namun bagaimana mencari jarak antar titik jika terdapat 20 dimensi. Hal ini akan menjadi sulit. Jika hanya terdapat beberapa titik sampel data, maka cukup mudah untuk menghitung dan mencari titik terdekat dengan k titik yang diinisialisasi secara random. Namun jika terdapat banyak sekali titik data (misalnya satu milyar buah data), maka perhitungan dan pencarian titik terdekat akan membutuhkan waktu yang lama. Proses tersebut dapat dipercepat, namun dibutuhkan struktur data yang lebih rumit seperti kD-Tree atau hashing.","title":"Kelebihan dan Kekurangan"},{"location":"#implementasi","text":"","title":"Implementasi"},{"location":"#tools","text":"Sebelum menerapkan konsep k-mean clustering pada studi kasus yang telah ditentukan, beberapa tools yang perlu dipersiapkan agar program yang kita rancang bisa dieksekusi dengan baik diantaranya: XAMPP Notepad ++ / Visual Code / Sublime dan lainnya Browser / Chrome Python 3.7 Berikut source code dan penjelasan untuk menyelesaikan study kasus tersebut dengan K-Means Clustering.","title":"Tools"},{"location":"#pertama","text":"buka XAMPP kemudian start apache dan MySQL nya","title":"Pertama"},{"location":"#kedua","text":"impor data di phpmyadmin, setelah kita impor akan muncul tampilan seperti berikut","title":"Kedua"},{"location":"#ketiga","text":"kita buat script connect databasenya menggunakan php <?php $server = \"localhost\"; $username = \"root\"; $password = \"\"; $database = \"gizi\"; // Koneksi dan memilih database di server mysql_connect($server,$username,$password) or die(\"Koneksi gagal\"); mysql_select_db($database) or die(\"Database tidak bisa dibuka\"); ?>","title":"ketiga"},{"location":"#keempat","text":"membuat tampilan data set ruspini yang terconnect dengan database menggunakan php dan html <?php error_reporting(0); include \"koneksi.php\"; echo \"<h2>Uji Data Set Ruspini</h2> <form method=POST action='aksi.php' enctype='multipart/form-data'> <table> <tr> <td>X</td> <td> : </td> <td> <input type=text name='x' maxlength=100 size=50> </td> </tr> <tr> <td>Y</td> <td> : </td> <td> <input type=text name='y' maxlength=100 size=50> </td> </tr> <tr><td colspan=2> <input type=submit value=Proses> <input type=button value=Batal onclick=self.history.back()></td></tr> </table> </form>\"; echo \"<h2>Tambah Data</h2> <form method=POST action='tambah.php' enctype='multipart/form-data'> <table> <tr> <td>X</td> <td> : </td> <td> <input type=text name='x' maxlength=100 size=50> </td> </tr> <tr> <td>Y</td> <td> : </td> <td> <input type=text name='y' maxlength=100 size=50> </td> </tr> <tr> <td>Kelas</td> <td> : </td> <td> <input type=text name='status' maxlength=100 size=50> </td> </tr> <tr><td colspan=2> <input type=submit value=Simpan> <input type=button value=Batal onclick=self.history.back()></td></tr> </table> </form>\"; /* echo \"<h2>Tambah data</h2> <form method=POST action='tambah.php' enctype='multipart/form-data'> <table> <tr><td>Nama Manggrove</td> <td> : </td><td><input type=text name='nama' maxlength=30 size=30></td></tr> <tr><td>Bentuk Tanaman</td> <td> : </td><td><input type=text name='bt' maxlength=10 size=10></td></tr> <tr><td>Bentuk Akar</td> <td> : </td><td><input type=text name='ba' maxlength=10 size=10></td></tr> <tr><td>Bentuk Buah</td> <td> : </td><td><input type=text name='bb' maxlength=10 size=10></td></tr> <tr><td>Bentuk Daun</td> <td> : </td><td><input type=text name='bd' maxlength=10 size=10></td></tr> <tr><td>Susunan Daun</td> <td> : </td><td><input type=text name='sd' maxlength=10 size=10></td></tr> <tr><td>Tata Letak Daun</td> <td> : </td><td><input type=text name='tld' maxlength=10 size=10></td></tr> <tr><td>Bentuk Ujung Daun</td> <td> : </td><td><input type=text name='bud' maxlength=10 size=10></td></tr> <tr><td>Letak Bunga</td> <td> : </td><td><input type=text name='lb' maxlength=10 size=10></td></tr> <tr><td>Rangkaian Bunga</td> <td> : </td><td><input type=text name='rb' maxlength=10 size=10></td></tr> <tr><td>Daun Mahkota Bunga</td> <td> : </td><td><input type=text name='dmb' maxlength=10 size=10></td></tr> <tr><td>Habitat Tempat Tumbuh</td> <td> : </td><td><input type=text name='htt' maxlength=10 size=10></td></tr> <tr><td colspan=2> <input type=submit value=Simpan> <input type=button value=Batal onclick=self.history.back()></td></tr> </table> </form>\"; */ echo \"========= data Training =========\"; $sql2 = mysql_query(\"SELECT * FROM data ORDER BY id ASC\"); echo \"<table> <thead> <th>Data </th> <th>Kelas</th> <th>X</th> <th>Y</th> </thead>\"; while($data = mysql_fetch_array($sql2)) { echo \"<tr> <td>$data[id]</td> <td>$data[status]</td> <td>$data[x]</td> <td>$data[y]</td> </tr>\"; } echo \"</table>\"; echo \"========= data perhitungan =========\"; $sqls = mysql_query(\"SELECT * FROM sementara ORDER BY id ASC\"); echo \"<table> <thead> <th>Data </th> <th>Kelas</th> <th>X</th> <th>Y</th> </thead>\"; while($data = mysql_fetch_array($sqls)) { echo \"<tr> <td>$data[id]</td> <td>$data[status]</td> <td>$data[x]</td> <td>$data[y]</td> <td>$data[jarak]</td> </tr>\"; } echo \"</table>\"; ?>","title":"keempat"},{"location":"#kelima","text":"kita buat script perhitungan KNN dengan mengimpor data X dan Y menggunakan php <?php error_reporting(0); include \"koneksi.php\"; $b_x = $_POST['x']; $b_y = $_POST['y']; if (empty($b_x) or empty($b_y)) { echo \"<script> alert('Ada yang belum anda isi'); window.location = 'javascript:history.go(-1)'; </script>\"; } else { //Membaca jumlah baris data pada database $sql = mysql_query(\"SELECT * FROM data ORDER BY id ASC\"); $numrows = mysql_num_rows($sql); //Menentukan nilai K /*$k=0.3 * $numrows; $k=round($k); $r=$k % 2; if($r!=0) { $k=$k+1; } else { $k=$k; }*/ $k=5; echo \"<b>Nilai K adalah sebesar $k </b><br><br>\"; //Perhitungan dengan KNN for ($i=1; $i <= $numrows; $i++) { $sql1 = mysql_query(\"SELECT * FROM data Where id = $i\"); while($data = mysql_fetch_array($sql1)) { //Pengurangan(KNN) $v1 = $b_x - $data[x]; $v2 = $b_y - $data[y]; //Pengkuadratan(KNN) $hit1 = (pow($v1,2)) + (pow($v2,2)); //Pengakaran(KNN) $hit2 = sqrt($hit1); //Penyimpanan perhitungan ke database sementara mysql_query(\"INSERT INTO sementara (id, jarak, x, y, status) VALUES ('$i', '$hit2', '$data[x]', '$data[y]', '$data[status]')\"); } } //data yang sudah d sorting dari data pertama sampai data nilai K $sql3 = mysql_query(\"SELECT * FROM `sementara` ORDER BY `sementara`.`jarak` ASC LIMIT 0 , $k\"); $x=1; while($data = mysql_fetch_array($sql3)) { //memasukkan data yang sudah di sorting mulai dari pertama sampai data nilai k ke dalam database sementara mysql_query(\"INSERT INTO urut (id, jarak, x, y, status) VALUES ('$x', '$data[jarak]', '$data[x]', '$data[y]', '$data[status]')\"); $x=$x+1; } $sqlrtes = mysql_query(\"SELECT * FROM urut ORDER BY id ASC LIMIT 0 , 1\"); while($datates = mysql_fetch_array($sqlrtes)) { //mencari hasil $sqlrx = mysql_query(\"SELECT * FROM urut ORDER BY id ASC\"); //$hasil_nam = mysql_fetch_array($sql_nam); while($datax = mysql_fetch_array($sqlrx)) { if($datax['jarak']=='0') { $Status = $datax['status']; $x = $datax['x']; $y = $datax['y']; echo \"<br>Terklasifikasi sebagai Kelas <b>$Status</b>, dengan X <b>$x</b>, dan Y <b>$y</b></b>\"; break; } else { $Status = $datax['status']; $x = $datax['x']; $y = $datax['y']; echo \"<br>Terklasifikasi sebagai Kelas <b>$Status</b>, dengan X <b>$x</b>, dan Y <b>$y</b></b>\"; break; } } } //langkah terakhir menghapus histori perhitungan pada database $sqls = mysql_query(\"SELECT * FROM sementara ORDER BY id ASC\"); $numrows1 = mysql_num_rows($sqls); for ($i=1; $i <= $numrows1; $i++) { mysql_query(\"DELETE FROM sementara WHERE id=$i\"); } $sql_urut = mysql_query(\"SELECT * FROM data ORDER BY id ASC\"); $numrows_urut = mysql_num_rows($sql_urut); for ($i=1; $i <= $numrows_urut; $i++) { mysql_query(\"DELETE FROM urut WHERE id=$i\"); } } ?>","title":"kelima"},{"location":"#keenam","text":"kita buat script penambahan data dengan mengimpor data X, Y dan kelas menggunakan php <?php error_reporting(0); include \"koneksi.php\"; $b_tinggi = $_POST['tinggi']; $b_berat = $_POST['berat']; $b_status = $_POST['status']; if (empty($b_tinggi) or empty($b_berat) or empty($b_status)) { echo \"<script>alert('Nama something belum anda isi');window.location = 'javascript:history.go(-1)'; </script>\"; } else { mysql_query(\"INSERT INTO data (tinggi, berat, status) VALUES ('$b_tinggi', '$b_berat', '$b_status')\"); echo \"<script>alert('Sukses');window.location = 'javascript:history.go(-1)'; </script>\"; } ?>","title":"keenam"},{"location":"#refrensi","text":"https://id.wikipedia.org/wiki/KNN https://id.wikipedia.org/wiki/K-means","title":"Refrensi"},{"location":"dcision-tree/","text":"Klasifikasi Pohon Keputusan dengan Python \u00b6 Dalam tutorial ini, pelajari Decision Tree Classification, langkah-langkah pemilihan atribut, dan bagaimana membangun dan mengoptimalkan Decision Tree Classifier menggunakan paket Python Scikit-learn. Sebagai manajer pemasaran, Anda menginginkan sekumpulan pelanggan yang kemungkinan besar akan membeli produk Anda. Ini adalah bagaimana Anda dapat menghemat anggaran pemasaran Anda dengan menemukan audiens Anda.Sebagai manajer pinjaman, Anda perlu mengidentifikasi aplikasi pinjaman berisiko untuk mencapai tingkat gagal bayar pinjaman yang lebih rendah. Proses mengklasifikasikan pelanggan ke dalam kelompok pelanggan potensial dan non-potensial atau aplikasi pinjaman yang aman atau berisiko dikenal sebagai masalah klasifikasi. Klasifikasi adalah proses dua langkah, langkah belajar dan langkah prediksi. Pada langkah pembelajaran, model dikembangkan berdasarkan data pelatihan yang diberikan. Pada langkah prediksi, model digunakan untuk memprediksi respons untuk data yang diberikan. Decision Tree adalah salah satu algoritma klasifikasi termudah dan populer untuk dipahami dan ditafsirkan. Ini dapat digunakan untuk masalah klasifikasi dan regresi. Dalam tutorial ini, Anda akan membahas topik-topik berikut: Algoritma Pohon Keputusan Bagaimana cara kerja algoritma Pohon Keputusan? Pengukuran Pilihan Atribut Keuntungan Informasi Rasio Keuntungan Indeks gini Mengoptimalkan Kinerja Pohon Keputusan Bangunan Classifier di Scikit-learn Pro dan kontra Kesimpulan Algoritma Pohon Keputusan \u00b6 Pohon keputusan adalah struktur pohon seperti bagan di mana simpul internal mewakili fitur (atau atribut), cabang mewakili aturan keputusan, dan setiap simpul daun mewakili hasilnya. Node paling atas dalam pohon keputusan dikenal sebagai simpul akar. Ia belajar mempartisi berdasarkan nilai atribut. Ini partisi pohon dengan cara rekursif panggilan partisi rekursif. Struktur seperti bagan alur ini membantu Anda dalam pengambilan keputusan. Ini visualisasi seperti diagram alur yang dengan mudah meniru pemikiran tingkat manusia. Itulah sebabnya pohon keputusan mudah dipahami dan ditafsirkan. Pohon Keputusan adalah jenis kotak putih dari algoritma ML. Ini berbagi logika pengambilan keputusan internal, yang tidak tersedia dalam jenis algoritma kotak hitam seperti Neural Network. Waktu pelatihannya lebih cepat dibandingkan dengan algoritma jaringan saraf. Kompleksitas waktu pohon keputusan adalah fungsi dari jumlah catatan dan jumlah atribut dalam data yang diberikan. Pohon keputusan adalah metode distribusi-bebas atau non-parametrik, yang tidak bergantung pada asumsi distribusi probabilitas. Pohon keputusan dapat menangani data dimensi tinggi dengan akurasi yang baik. Bagaimana cara kerja algoritma Pohon Keputusan? \u00b6 Gagasan dasar di balik algoritma pohon keputusan adalah sebagai berikut: Pilih atribut terbaik menggunakan Attribution Selection Measures (ASM) untuk membagi catatan. Jadikan atribut itu sebagai simpul keputusan dan pisahkan dataset menjadi himpunan bagian yang lebih kecil. Mulailah membangun pohon dengan mengulangi proses ini secara rekursif untuk setiap anak sampai salah satu dari kondisi tersebut akan cocok: Semua tupel memiliki nilai atribut yang sama. Tidak ada lagi atribut yang tersisa. Tidak ada contoh lagi. Pengukuran Pilihan Atribut \u00b6 Ukuran pemilihan atribut adalah heuristik untuk memilih kriteria pemisahan yang membagi data menjadi cara terbaik. Ia juga dikenal sebagai aturan pemisahan karena membantu kita untuk menentukan breakpoints untuk tuple pada node yang diberikan. ASM memberikan peringkat untuk setiap fitur (atau atribut) dengan menjelaskan dataset yang diberikan. Atribut skor terbaik akan dipilih sebagai atribut pemisahan ( Sumber ). Dalam kasus atribut bernilai kontinu, titik perpecahan untuk cabang juga perlu ditentukan. Ukuran seleksi yang paling populer adalah Information Gain, Gain Ratio, dan Gini Index. Keuntungan Informasi \u00b6 Shannon menemukan konsep entropi, yang mengukur ketidakmurnian set input.Dalam fisika dan matematika, entropi disebut sebagai keacakan atau ketidakmurnian dalam sistem. Dalam teori informasi, ini mengacu pada ketidakmurnian dalam sekelompok contoh. Keuntungan informasi adalah berkurangnya entropi. Informasi gain menghitung perbedaan antara entropi sebelum split dan rata-rata entropi setelah split dari dataset berdasarkan nilai atribut yang diberikan. Algoritma decision tree ID3 (Iterative Dichotomiser) menggunakan informasi gain. Di mana, Pi adalah probabilitas bahwa tuple arbitrer di D milik kelas Ci. Dimana, Info (D) adalah jumlah rata-rata informasi yang diperlukan untuk mengidentifikasi label kelas tuple di D. | Dj | / | D | bertindak sebagai bobot partisi j. InfoA (D) adalah informasi yang diharapkan diperlukan untuk mengklasifikasikan tuple dari D berdasarkan pada partisi oleh A. Atribut A dengan gain informasi tertinggi, Gain (A), dipilih sebagai atribut pemisahan pada simpul N (). Rasio Keuntungan \u00b6 Keuntungan informasi bias untuk atribut dengan banyak hasil. Itu berarti lebih suka atribut dengan sejumlah besar nilai yang berbeda. Misalnya, pertimbangkan atribut dengan pengidentifikasi unik seperti customer_ID memiliki nol info (D) karena partisi murni. Ini memaksimalkan perolehan informasi dan menciptakan partisi yang tidak berguna. C4.5, peningkatan ID3, menggunakan ekstensi untuk mendapatkan informasi yang dikenal sebagai rasio keuntungan. Rasio perolehan menangani masalah bias dengan menormalkan perolehan informasi menggunakan Split Info. Implementasi Java dari algoritma C4.5 dikenal sebagai J48, yang tersedia di alat penambangan data WEKA. Dimana, | Dj | / | D | bertindak sebagai bobot partisi j. v adalah jumlah nilai diskrit dalam atribut A. Rasio gain dapat didefinisikan sebagai Atribut dengan rasio gain tertinggi dipilih sebagai atribut pemisahan ( Sumber ). Indeks gini \u00b6 Algoritma decision tree lain, CART (Classification and Regression Tree) menggunakan metode Gini untuk membuat poin split. Di mana, pi adalah probabilitas bahwa sebuah tuple dalam D milik kelas Ci. Indeks Gini mempertimbangkan pemisahan biner untuk setiap atribut. Anda dapat menghitung jumlah pembobolan dari setiap partisi. Jika pemisahan biner pada atribut A data partisi D menjadi D1 dan D2, indeks Gini D adalah: Dalam hal atribut bernilai diskrit, subset yang memberikan indeks gini minimum untuk yang dipilih dipilih sebagai atribut pemisahan. Dalam kasus atribut bernilai kontinu, strateginya adalah memilih setiap pasangan nilai yang berdekatan sebagai titik perpecahan dan titik yang mungkin dengan indeks gini yang lebih kecil dipilih sebagai titik pemisahan. Atribut dengan indeks minimum Gini dipilih sebagai atribut pemisahan. Gedung Pengklasifikasian Pohon Keputusan di Scikit-learn \u00b6 Mengimpor Perpustakaan yang Diperlukan \u00b6 Pertama mari kita memuat perpustakaan yang diperlukan # Load libraries import pandas as pd from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier from sklearn.model_selection import train_test_split # Import train_test_split function from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation Memuat data \u00b6 Pertama mari kita memuat dataset Pima Indian Diabetes yang dibutuhkan menggunakan fungsi baca CSV panda. Anda dapat mengunduh data di sini . col_names = ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'label'] # load dataset pima = pd.read_csv(\"pima-indians-diabetes.csv\", header=None, names=col_names) pima.head() Pemilihan Fitur \u00b6 Di sini, Anda perlu membagi kolom yang diberikan menjadi dua jenis variabel dependen (atau variabel target) dan variabel independen (atau variabel fitur). #split dataset in features and target variable feature_cols = ['pregnant', 'insulin', 'bmi', 'age','glucose','bp','pedigree'] X = pima[feature_cols] # Features y = pima.label # Target variable Memisahkan Data \u00b6 Untuk memahami kinerja model, membagi dataset ke dalam set pelatihan dan set tes adalah strategi yang baik. Mari kita pisahkan dataset dengan menggunakan function train_test_split (). Anda harus melewati 3 parameter fitur, target, dan ukuran test_set. # Split dataset into training set and test set X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test Membangun Model Pohon Keputusan \u00b6 Mari kita membuat Model Pohon Keputusan menggunakan Scikit-belajar. # Create Decision Tree classifer object clf = DecisionTreeClassifier() # Train Decision Tree Classifer clf = clf.fit(X_train,y_train) #Predict the response for test dataset y_pred = clf.predict(X_test) Mengevaluasi Model \u00b6 Mari kita perkirakan, seberapa akurat classifier atau model dapat memprediksi jenis kultivar. Akurasi dapat dihitung dengan membandingkan nilai set tes aktual dan nilai prediksi. # Model Accuracy, how often is the classifier correct? print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred)) Accuracy: 0.6753246753246753 Nah, Anda mendapat tingkat klasifikasi 67,53%, dianggap sebagai akurasi yang baik. Anda dapat meningkatkan akurasi ini dengan menyetel parameter dalam Decision Tree Algorithm. Memvisualisasikan Pohon Keputusan \u00b6 Anda dapat menggunakan fungsi export_graphviz dari Scikit - learn untuk menampilkan pohon dalam notebook Jupyter. Untuk merencanakan pohon, Anda juga perlu menginstal graphviz dan pydotplus. pip install graphviz pip install pydotplus Fungsi export_graphviz mengubah classifier pohon keputusan menjadi file dot dan pydotplus mengubah file dot ini menjadi png atau bentuk yang dapat ditampilkan di Jupyter. from sklearn.tree import export_graphviz from sklearn.externals.six import StringIO from IPython.display import Image import pydotplus dot_data = StringIO() export_graphviz(clf, out_file=dot_data, filled=True, rounded=True, special_characters=True,feature_names = feature_cols,class_names=['0','1']) graph = pydotplus.graph_from_dot_data(dot_data.getvalue()) graph.write_png('diabetes.png') Image(graph.create_png()) Dalam bagan pohon keputusan, setiap simpul internal memiliki aturan keputusan yang membagi data. Gini disebut sebagai rasio Gini, yang mengukur ketidakmurnian simpul. Anda dapat mengatakan bahwa sebuah simpul adalah murni ketika semua catatan milik kelas yang sama, simpul tersebut dikenal sebagai simpul daun. Di sini, pohon yang dihasilkan tidak dilepas. Pohon tanpa ikatan ini tidak bisa dijelaskan dan tidak mudah dipahami. Di bagian selanjutnya, mari optimalkan dengan pemangkasan. Mengoptimalkan Kinerja Pohon Keputusan \u00b6 kriteria: opsional (default = \u201dgini\u201d) atau Pilih ukuran pemilihan atribut : Parameter ini memungkinkan kita untuk menggunakan ukuran pemilihan atribut yang berbeda-beda. Kriteria yang didukung adalah \"gini\" untuk indeks Gini dan \"entropi\" untuk perolehan informasi. splitter: string, opsional (default = \u201dbest\u201d) atau Split Strategy : Parameter ini memungkinkan kita untuk memilih strategi split. Strategi yang didukung adalah \"terbaik\" untuk memilih split terbaik dan \"acak\" untuk memilih split acak terbaik. max_depth: int atau None, opsional (default = None) atau Maximum Depth of a Tree : Kedalaman maksimum pohon. Jika tidak ada, maka node diperluas hingga semua daun mengandung kurang dari sampel min_samples_split. Nilai kedalaman maksimum yang lebih tinggi menyebabkan overfitting, dan nilai yang lebih rendah menyebabkan underfitting ( Sumber ). Dalam Scikit-belajar, optimalisasi classifier pohon keputusan dilakukan hanya dengan pra-pemangkasan. Kedalaman maksimum pohon dapat digunakan sebagai variabel kontrol untuk pra-pemangkasan. Dalam contoh berikut ini, Anda bisa memplot pohon keputusan pada data yang sama dengan max_depth = 3. Selain parameter pra-pemangkasan, Anda juga dapat mencoba ukuran pemilihan atribut lainnya seperti entropi. # Create Decision Tree classifer object clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3) # Train Decision Tree Classifer clf = clf.fit(X_train,y_train) #Predict the response for test dataset y_pred = clf.predict(X_test) # Model Accuracy, how often is the classifier correct? print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred)) Accuracy: 0.7705627705627706 Nah, tingkat klasifikasi meningkat menjadi 77,05%, yang merupakan akurasi yang lebih baik daripada model sebelumnya. Memvisualisasikan Pohon Keputusan \u00b6 from sklearn.externals.six import StringIO from IPython.display import Image from sklearn.tree import export_graphviz import pydotplus dot_data = StringIO() export_graphviz(clf, out_file=dot_data, filled=True, rounded=True, special_characters=True, feature_names = feature_cols,class_names=['0','1']) graph = pydotplus.graph_from_dot_data(dot_data.getvalue()) graph.write_png('diabetes.png') Image(graph.create_png()) Model pemangkasan ini tidak terlalu rumit, dapat dijelaskan, dan mudah dipahami daripada plot model pohon keputusan sebelumnya. Pro \u00b6 Pohon keputusan mudah diinterpretasikan dan divisualisasikan. Ini dapat dengan mudah menangkap pola Non-linear. Ini membutuhkan lebih sedikit pemrosesan data dari pengguna, misalnya, tidak perlu menormalkan kolom. Ini dapat digunakan untuk rekayasa fitur seperti memprediksi nilai yang hilang, cocok untuk pemilihan variabel. Pohon keputusan tidak memiliki asumsi tentang distribusi karena sifat non-parametrik dari algoritma. ( Sumber ) Cons \u00b6 Peka terhadap data berisik. Itu bisa menyesuaikan data yang bising. Variasi kecil (atau varians) dalam data dapat menghasilkan pohon keputusan yang berbeda. Ini dapat dikurangi dengan mengantongi dan meningkatkan algoritma. Pohon keputusan bias dengan dataset ketidakseimbangan, jadi disarankan untuk menyeimbangkan dataset sebelum membuat pohon keputusan. Kesimpulan \u00b6 Selamat, Anda telah berhasil sampai akhir tutorial ini! Dalam tutorial ini, Anda membahas banyak detail tentang Decision Tree; Ini bekerja, langkah-langkah pemilihan atribut seperti Information Gain, Gain Ratio, dan Gini Index, pembuatan model pohon keputusan, visualisasi dan evaluasi pada dataset diabetes menggunakan paket Python Scikit-learning. Juga membahas pro, kontra, dan mengoptimalkan kinerja Decision Tree menggunakan penyetelan parameter. Mudah-mudahan, sekarang Anda dapat menggunakan algoritma pohon Keputusan untuk menganalisis kumpulan data Anda sendiri. Jika Anda ingin mempelajari lebih lanjut tentang Pembelajaran Mesin dengan Python, ambil Pembelajaran Mesin DataCamp dengan Model Berbasis Pohon dalam kursus Python .","title":"Klasifikasi Pohon Keputusan dengan Python"},{"location":"dcision-tree/#klasifikasi-pohon-keputusan-dengan-python","text":"Dalam tutorial ini, pelajari Decision Tree Classification, langkah-langkah pemilihan atribut, dan bagaimana membangun dan mengoptimalkan Decision Tree Classifier menggunakan paket Python Scikit-learn. Sebagai manajer pemasaran, Anda menginginkan sekumpulan pelanggan yang kemungkinan besar akan membeli produk Anda. Ini adalah bagaimana Anda dapat menghemat anggaran pemasaran Anda dengan menemukan audiens Anda.Sebagai manajer pinjaman, Anda perlu mengidentifikasi aplikasi pinjaman berisiko untuk mencapai tingkat gagal bayar pinjaman yang lebih rendah. Proses mengklasifikasikan pelanggan ke dalam kelompok pelanggan potensial dan non-potensial atau aplikasi pinjaman yang aman atau berisiko dikenal sebagai masalah klasifikasi. Klasifikasi adalah proses dua langkah, langkah belajar dan langkah prediksi. Pada langkah pembelajaran, model dikembangkan berdasarkan data pelatihan yang diberikan. Pada langkah prediksi, model digunakan untuk memprediksi respons untuk data yang diberikan. Decision Tree adalah salah satu algoritma klasifikasi termudah dan populer untuk dipahami dan ditafsirkan. Ini dapat digunakan untuk masalah klasifikasi dan regresi. Dalam tutorial ini, Anda akan membahas topik-topik berikut: Algoritma Pohon Keputusan Bagaimana cara kerja algoritma Pohon Keputusan? Pengukuran Pilihan Atribut Keuntungan Informasi Rasio Keuntungan Indeks gini Mengoptimalkan Kinerja Pohon Keputusan Bangunan Classifier di Scikit-learn Pro dan kontra Kesimpulan","title":"Klasifikasi Pohon Keputusan dengan Python"},{"location":"dcision-tree/#algoritma-pohon-keputusan","text":"Pohon keputusan adalah struktur pohon seperti bagan di mana simpul internal mewakili fitur (atau atribut), cabang mewakili aturan keputusan, dan setiap simpul daun mewakili hasilnya. Node paling atas dalam pohon keputusan dikenal sebagai simpul akar. Ia belajar mempartisi berdasarkan nilai atribut. Ini partisi pohon dengan cara rekursif panggilan partisi rekursif. Struktur seperti bagan alur ini membantu Anda dalam pengambilan keputusan. Ini visualisasi seperti diagram alur yang dengan mudah meniru pemikiran tingkat manusia. Itulah sebabnya pohon keputusan mudah dipahami dan ditafsirkan. Pohon Keputusan adalah jenis kotak putih dari algoritma ML. Ini berbagi logika pengambilan keputusan internal, yang tidak tersedia dalam jenis algoritma kotak hitam seperti Neural Network. Waktu pelatihannya lebih cepat dibandingkan dengan algoritma jaringan saraf. Kompleksitas waktu pohon keputusan adalah fungsi dari jumlah catatan dan jumlah atribut dalam data yang diberikan. Pohon keputusan adalah metode distribusi-bebas atau non-parametrik, yang tidak bergantung pada asumsi distribusi probabilitas. Pohon keputusan dapat menangani data dimensi tinggi dengan akurasi yang baik.","title":"Algoritma Pohon Keputusan"},{"location":"dcision-tree/#bagaimana-cara-kerja-algoritma-pohon-keputusan","text":"Gagasan dasar di balik algoritma pohon keputusan adalah sebagai berikut: Pilih atribut terbaik menggunakan Attribution Selection Measures (ASM) untuk membagi catatan. Jadikan atribut itu sebagai simpul keputusan dan pisahkan dataset menjadi himpunan bagian yang lebih kecil. Mulailah membangun pohon dengan mengulangi proses ini secara rekursif untuk setiap anak sampai salah satu dari kondisi tersebut akan cocok: Semua tupel memiliki nilai atribut yang sama. Tidak ada lagi atribut yang tersisa. Tidak ada contoh lagi.","title":"Bagaimana cara kerja algoritma Pohon Keputusan?"},{"location":"dcision-tree/#pengukuran-pilihan-atribut","text":"Ukuran pemilihan atribut adalah heuristik untuk memilih kriteria pemisahan yang membagi data menjadi cara terbaik. Ia juga dikenal sebagai aturan pemisahan karena membantu kita untuk menentukan breakpoints untuk tuple pada node yang diberikan. ASM memberikan peringkat untuk setiap fitur (atau atribut) dengan menjelaskan dataset yang diberikan. Atribut skor terbaik akan dipilih sebagai atribut pemisahan ( Sumber ). Dalam kasus atribut bernilai kontinu, titik perpecahan untuk cabang juga perlu ditentukan. Ukuran seleksi yang paling populer adalah Information Gain, Gain Ratio, dan Gini Index.","title":"Pengukuran Pilihan Atribut"},{"location":"dcision-tree/#keuntungan-informasi","text":"Shannon menemukan konsep entropi, yang mengukur ketidakmurnian set input.Dalam fisika dan matematika, entropi disebut sebagai keacakan atau ketidakmurnian dalam sistem. Dalam teori informasi, ini mengacu pada ketidakmurnian dalam sekelompok contoh. Keuntungan informasi adalah berkurangnya entropi. Informasi gain menghitung perbedaan antara entropi sebelum split dan rata-rata entropi setelah split dari dataset berdasarkan nilai atribut yang diberikan. Algoritma decision tree ID3 (Iterative Dichotomiser) menggunakan informasi gain. Di mana, Pi adalah probabilitas bahwa tuple arbitrer di D milik kelas Ci. Dimana, Info (D) adalah jumlah rata-rata informasi yang diperlukan untuk mengidentifikasi label kelas tuple di D. | Dj | / | D | bertindak sebagai bobot partisi j. InfoA (D) adalah informasi yang diharapkan diperlukan untuk mengklasifikasikan tuple dari D berdasarkan pada partisi oleh A. Atribut A dengan gain informasi tertinggi, Gain (A), dipilih sebagai atribut pemisahan pada simpul N ().","title":"Keuntungan Informasi"},{"location":"dcision-tree/#rasio-keuntungan","text":"Keuntungan informasi bias untuk atribut dengan banyak hasil. Itu berarti lebih suka atribut dengan sejumlah besar nilai yang berbeda. Misalnya, pertimbangkan atribut dengan pengidentifikasi unik seperti customer_ID memiliki nol info (D) karena partisi murni. Ini memaksimalkan perolehan informasi dan menciptakan partisi yang tidak berguna. C4.5, peningkatan ID3, menggunakan ekstensi untuk mendapatkan informasi yang dikenal sebagai rasio keuntungan. Rasio perolehan menangani masalah bias dengan menormalkan perolehan informasi menggunakan Split Info. Implementasi Java dari algoritma C4.5 dikenal sebagai J48, yang tersedia di alat penambangan data WEKA. Dimana, | Dj | / | D | bertindak sebagai bobot partisi j. v adalah jumlah nilai diskrit dalam atribut A. Rasio gain dapat didefinisikan sebagai Atribut dengan rasio gain tertinggi dipilih sebagai atribut pemisahan ( Sumber ).","title":"Rasio Keuntungan"},{"location":"dcision-tree/#indeks-gini","text":"Algoritma decision tree lain, CART (Classification and Regression Tree) menggunakan metode Gini untuk membuat poin split. Di mana, pi adalah probabilitas bahwa sebuah tuple dalam D milik kelas Ci. Indeks Gini mempertimbangkan pemisahan biner untuk setiap atribut. Anda dapat menghitung jumlah pembobolan dari setiap partisi. Jika pemisahan biner pada atribut A data partisi D menjadi D1 dan D2, indeks Gini D adalah: Dalam hal atribut bernilai diskrit, subset yang memberikan indeks gini minimum untuk yang dipilih dipilih sebagai atribut pemisahan. Dalam kasus atribut bernilai kontinu, strateginya adalah memilih setiap pasangan nilai yang berdekatan sebagai titik perpecahan dan titik yang mungkin dengan indeks gini yang lebih kecil dipilih sebagai titik pemisahan. Atribut dengan indeks minimum Gini dipilih sebagai atribut pemisahan.","title":"Indeks gini"},{"location":"dcision-tree/#gedung-pengklasifikasian-pohon-keputusan-di-scikit-learn","text":"","title":"Gedung Pengklasifikasian Pohon Keputusan di Scikit-learn"},{"location":"dcision-tree/#mengimpor-perpustakaan-yang-diperlukan","text":"Pertama mari kita memuat perpustakaan yang diperlukan # Load libraries import pandas as pd from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier from sklearn.model_selection import train_test_split # Import train_test_split function from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation","title":"Mengimpor Perpustakaan yang Diperlukan"},{"location":"dcision-tree/#memuat-data","text":"Pertama mari kita memuat dataset Pima Indian Diabetes yang dibutuhkan menggunakan fungsi baca CSV panda. Anda dapat mengunduh data di sini . col_names = ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'label'] # load dataset pima = pd.read_csv(\"pima-indians-diabetes.csv\", header=None, names=col_names) pima.head()","title":"Memuat data"},{"location":"dcision-tree/#pemilihan-fitur","text":"Di sini, Anda perlu membagi kolom yang diberikan menjadi dua jenis variabel dependen (atau variabel target) dan variabel independen (atau variabel fitur). #split dataset in features and target variable feature_cols = ['pregnant', 'insulin', 'bmi', 'age','glucose','bp','pedigree'] X = pima[feature_cols] # Features y = pima.label # Target variable","title":"Pemilihan Fitur"},{"location":"dcision-tree/#memisahkan-data","text":"Untuk memahami kinerja model, membagi dataset ke dalam set pelatihan dan set tes adalah strategi yang baik. Mari kita pisahkan dataset dengan menggunakan function train_test_split (). Anda harus melewati 3 parameter fitur, target, dan ukuran test_set. # Split dataset into training set and test set X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test","title":"Memisahkan Data"},{"location":"dcision-tree/#membangun-model-pohon-keputusan","text":"Mari kita membuat Model Pohon Keputusan menggunakan Scikit-belajar. # Create Decision Tree classifer object clf = DecisionTreeClassifier() # Train Decision Tree Classifer clf = clf.fit(X_train,y_train) #Predict the response for test dataset y_pred = clf.predict(X_test)","title":"Membangun Model Pohon Keputusan"},{"location":"dcision-tree/#mengevaluasi-model","text":"Mari kita perkirakan, seberapa akurat classifier atau model dapat memprediksi jenis kultivar. Akurasi dapat dihitung dengan membandingkan nilai set tes aktual dan nilai prediksi. # Model Accuracy, how often is the classifier correct? print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred)) Accuracy: 0.6753246753246753 Nah, Anda mendapat tingkat klasifikasi 67,53%, dianggap sebagai akurasi yang baik. Anda dapat meningkatkan akurasi ini dengan menyetel parameter dalam Decision Tree Algorithm.","title":"Mengevaluasi Model"},{"location":"dcision-tree/#memvisualisasikan-pohon-keputusan","text":"Anda dapat menggunakan fungsi export_graphviz dari Scikit - learn untuk menampilkan pohon dalam notebook Jupyter. Untuk merencanakan pohon, Anda juga perlu menginstal graphviz dan pydotplus. pip install graphviz pip install pydotplus Fungsi export_graphviz mengubah classifier pohon keputusan menjadi file dot dan pydotplus mengubah file dot ini menjadi png atau bentuk yang dapat ditampilkan di Jupyter. from sklearn.tree import export_graphviz from sklearn.externals.six import StringIO from IPython.display import Image import pydotplus dot_data = StringIO() export_graphviz(clf, out_file=dot_data, filled=True, rounded=True, special_characters=True,feature_names = feature_cols,class_names=['0','1']) graph = pydotplus.graph_from_dot_data(dot_data.getvalue()) graph.write_png('diabetes.png') Image(graph.create_png()) Dalam bagan pohon keputusan, setiap simpul internal memiliki aturan keputusan yang membagi data. Gini disebut sebagai rasio Gini, yang mengukur ketidakmurnian simpul. Anda dapat mengatakan bahwa sebuah simpul adalah murni ketika semua catatan milik kelas yang sama, simpul tersebut dikenal sebagai simpul daun. Di sini, pohon yang dihasilkan tidak dilepas. Pohon tanpa ikatan ini tidak bisa dijelaskan dan tidak mudah dipahami. Di bagian selanjutnya, mari optimalkan dengan pemangkasan.","title":"Memvisualisasikan Pohon Keputusan"},{"location":"dcision-tree/#mengoptimalkan-kinerja-pohon-keputusan","text":"kriteria: opsional (default = \u201dgini\u201d) atau Pilih ukuran pemilihan atribut : Parameter ini memungkinkan kita untuk menggunakan ukuran pemilihan atribut yang berbeda-beda. Kriteria yang didukung adalah \"gini\" untuk indeks Gini dan \"entropi\" untuk perolehan informasi. splitter: string, opsional (default = \u201dbest\u201d) atau Split Strategy : Parameter ini memungkinkan kita untuk memilih strategi split. Strategi yang didukung adalah \"terbaik\" untuk memilih split terbaik dan \"acak\" untuk memilih split acak terbaik. max_depth: int atau None, opsional (default = None) atau Maximum Depth of a Tree : Kedalaman maksimum pohon. Jika tidak ada, maka node diperluas hingga semua daun mengandung kurang dari sampel min_samples_split. Nilai kedalaman maksimum yang lebih tinggi menyebabkan overfitting, dan nilai yang lebih rendah menyebabkan underfitting ( Sumber ). Dalam Scikit-belajar, optimalisasi classifier pohon keputusan dilakukan hanya dengan pra-pemangkasan. Kedalaman maksimum pohon dapat digunakan sebagai variabel kontrol untuk pra-pemangkasan. Dalam contoh berikut ini, Anda bisa memplot pohon keputusan pada data yang sama dengan max_depth = 3. Selain parameter pra-pemangkasan, Anda juga dapat mencoba ukuran pemilihan atribut lainnya seperti entropi. # Create Decision Tree classifer object clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3) # Train Decision Tree Classifer clf = clf.fit(X_train,y_train) #Predict the response for test dataset y_pred = clf.predict(X_test) # Model Accuracy, how often is the classifier correct? print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred)) Accuracy: 0.7705627705627706 Nah, tingkat klasifikasi meningkat menjadi 77,05%, yang merupakan akurasi yang lebih baik daripada model sebelumnya.","title":"Mengoptimalkan Kinerja Pohon Keputusan"},{"location":"dcision-tree/#memvisualisasikan-pohon-keputusan_1","text":"from sklearn.externals.six import StringIO from IPython.display import Image from sklearn.tree import export_graphviz import pydotplus dot_data = StringIO() export_graphviz(clf, out_file=dot_data, filled=True, rounded=True, special_characters=True, feature_names = feature_cols,class_names=['0','1']) graph = pydotplus.graph_from_dot_data(dot_data.getvalue()) graph.write_png('diabetes.png') Image(graph.create_png()) Model pemangkasan ini tidak terlalu rumit, dapat dijelaskan, dan mudah dipahami daripada plot model pohon keputusan sebelumnya.","title":"Memvisualisasikan Pohon Keputusan"},{"location":"dcision-tree/#pro","text":"Pohon keputusan mudah diinterpretasikan dan divisualisasikan. Ini dapat dengan mudah menangkap pola Non-linear. Ini membutuhkan lebih sedikit pemrosesan data dari pengguna, misalnya, tidak perlu menormalkan kolom. Ini dapat digunakan untuk rekayasa fitur seperti memprediksi nilai yang hilang, cocok untuk pemilihan variabel. Pohon keputusan tidak memiliki asumsi tentang distribusi karena sifat non-parametrik dari algoritma. ( Sumber )","title":"Pro"},{"location":"dcision-tree/#cons","text":"Peka terhadap data berisik. Itu bisa menyesuaikan data yang bising. Variasi kecil (atau varians) dalam data dapat menghasilkan pohon keputusan yang berbeda. Ini dapat dikurangi dengan mengantongi dan meningkatkan algoritma. Pohon keputusan bias dengan dataset ketidakseimbangan, jadi disarankan untuk menyeimbangkan dataset sebelum membuat pohon keputusan.","title":"Cons"},{"location":"dcision-tree/#kesimpulan","text":"Selamat, Anda telah berhasil sampai akhir tutorial ini! Dalam tutorial ini, Anda membahas banyak detail tentang Decision Tree; Ini bekerja, langkah-langkah pemilihan atribut seperti Information Gain, Gain Ratio, dan Gini Index, pembuatan model pohon keputusan, visualisasi dan evaluasi pada dataset diabetes menggunakan paket Python Scikit-learning. Juga membahas pro, kontra, dan mengoptimalkan kinerja Decision Tree menggunakan penyetelan parameter. Mudah-mudahan, sekarang Anda dapat menggunakan algoritma pohon Keputusan untuk menganalisis kumpulan data Anda sendiri. Jika Anda ingin mempelajari lebih lanjut tentang Pembelajaran Mesin dengan Python, ambil Pembelajaran Mesin DataCamp dengan Model Berbasis Pohon dalam kursus Python .","title":"Kesimpulan"},{"location":"penyusun/","text":"Penyusun \u00b6 Nama : Ainun Nawawi Nim : 170441100110 Program Studi : Sistem Informasi Prodi : Sistem Informasi Universitas : Trunojoyo Madura","title":"Penyusun"},{"location":"penyusun/#penyusun","text":"Nama : Ainun Nawawi Nim : 170441100110 Program Studi : Sistem Informasi Prodi : Sistem Informasi Universitas : Trunojoyo Madura","title":"Penyusun"}]}